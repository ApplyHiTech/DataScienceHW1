{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as sqlFunctions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from operator import add\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "sc = pyspark.SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Full original training set\n",
    "raw_full_train = sc.textFile(\"dac/train.txt\")\n",
    "\n",
    "# Final test set split\n",
    "raw_final_test = sc.textFile(\"dac/split/test.txt\")  # Do not touch during training\n",
    "\n",
    "# Training set splits\n",
    "raw_test_3m = sc.textFile(\"dac/split/test_3m.txt\")\n",
    "raw_train_5m = sc.textFile(\"dac/split/train_5m.txt\")\n",
    "raw_validation_2m = sc.textFile(\"dac/split/train_5m.txt\")\n",
    "\n",
    "# Debug set\n",
    "raw_small_train = sc.textFile(\"dac/small-train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_value(index, value):\n",
    "    if index < 14:\n",
    "        return int(value) if value else None\n",
    "    else:\n",
    "        return value if value else None\n",
    "\n",
    "def convert_line(line):\n",
    "    return [convert_value(i, value) for i, value in enumerate(line.split(\"\\t\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change the data types of the datasets so that the RDD's include Int's and Strings. \n",
    "full_train = raw_full_train.map(convert_line)\n",
    "final_test = raw_final_test.map(convert_line)\n",
    "test_3m = raw_test_3m.map(convert_line)\n",
    "train_5m = raw_train_5m.map(convert_line)\n",
    "validation_2m = raw_validation_2m.map(convert_line)\n",
    "\n",
    "#debug = raw_small_train.map(convert_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def int_column_histogram(col_num, col,numb_bins=10):\n",
    "    bins, counts = col.histogram(numb_bins)\n",
    "    total = sum(counts)    \n",
    "    print \"Column %d histogram\\n\\tBins=%s\\n\\tCounts=%s (total=%d)\" % (col_num, bins, counts, total)\n",
    "    # TODO: display graph of histogram\n",
    "    # TODO: better buckets for histogram (smart sub-dividing)\n",
    "        #sum the counts\n",
    "        #max of the counts\n",
    "        #if  > 25%\n",
    "    return bins,counts\n",
    "\n",
    "def int_columns_histograms(data,numb_bins=10):\n",
    "    bins=[]; counts=[]\n",
    "    for i, col in enumerate(column_iter(data)):\n",
    "        col_num = i + 1\n",
    "        if is_integer_col_num(col_num):\n",
    "            bins1,counts1 = int_column_histogram(col_num, col,numb_bins)\n",
    "            bins.append(bins1) #bin values\n",
    "            counts.append(counts1) #count inside bins\n",
    "            \n",
    "    return bins,counts\n",
    "\n",
    "def bin_range_labels(bins):\n",
    "    #Nicely display these.\n",
    "    \"{:0,.3f} - {:0,.0f}\"\n",
    "    return [\"%s---%s\" % (\"{:.1E}\".format((bins[i])),\"{:.2E}\".format((bins[i+1]))) for i in range(len(bins) - 1)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_column_num(data, col_num):\n",
    "    return data.map(lambda row: row[col_num])\n",
    "\n",
    "def column_filter_null(column):\n",
    "    return column.filter(lambda row: row is not None)\n",
    "\n",
    "def column_count(data):\n",
    "    return len(data.take(1)[0])\n",
    "\n",
    "def is_integer_col_num(col_num):\n",
    "    return col_num > 1 and col_num < 15\n",
    "\n",
    "def is_label_col_num(col_num):\n",
    "    return col_num == 1\n",
    "\n",
    "def is_categorical_col_num(col_num):\n",
    "    return col_num >= 15\n",
    "\n",
    "def column_iter(data):\n",
    "    for i in range(column_count(data)):\n",
    "         yield get_column_num(data, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cat_columns_histogram(data,numb_bins=10):\n",
    "    hashes=[]; counts_all=[]; remainder=[];\n",
    "    \n",
    "    for i, col in enumerate(column_iter(data)):\n",
    "        col_num = i + 1\n",
    "        if is_categorical_col_num(col_num):\n",
    "            key_counts = col.map(lambda key: (key, 1)).reduceByKey(add)\n",
    "            sorted_counts = sorted(key_counts.collect(), key=lambda t: t[1], reverse=True)\n",
    "            labels = [v[0] for v in sorted_counts]\n",
    "            counts = [v[1] for v in sorted_counts]\n",
    "            print i\n",
    "            print col\n",
    "            hashes.append(labels[:numb_bins]) #bin values\n",
    "            counts_all.append(counts[:numb_bins]) #count inside bins\n",
    "            remainder.append(sum(counts[numb_bins:]))\n",
    "            \n",
    "    return hashes,counts_all,remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This represents the Histograms for Features. \n",
    "# For Integer Feature we do not compute \"Other Values\"\n",
    "# \n",
    "# x_values = 1D array of the x_values {bins OR category names}\n",
    "# y_values = 1D array of the y_values {counts of uniques in bins or category name}\n",
    "# isCategory = True if feature is category. \n",
    "#            = False if feature is integer.\n",
    "# Z_other_values = sum of the counts of the remaining categories for category feature.\n",
    "#\n",
    "#\n",
    "def disp_Histogram(x_values,y_values,isCategory, column_numb,z_other_value=0):\n",
    "        range_x = min(len(x_values),10)\n",
    "        x1 = np.arange(range_x)\n",
    "        x2 = []\n",
    "        \n",
    "        \n",
    "        # Category Feature\n",
    "        if (isCategory):\n",
    "            type_of_feature = \"Category\"\n",
    "            x_label = \"Category as a Hashed value\"\n",
    "            #Add Other column\n",
    "            for i in x_values: \n",
    "                x2.append(str(i))\n",
    "            \n",
    "            x1 = np.append(x1,10)\n",
    "            x2.append('Other')\n",
    "            #print \"HI\",z_other_value\n",
    "            y_values.append(z_other_value)\n",
    "\n",
    "        # Integer Feature\n",
    "        else: \n",
    "            type_of_feature = \"Integer\"\n",
    "            x_label = \"Bins of Integer values\"\n",
    "            x2 = bin_range_labels(x_values)\n",
    "\n",
    "        \n",
    "        plt.title('%s Feature %s Histogram' % (type_of_feature,column_numb))\n",
    "        plt.ylabel('Count of values')\n",
    "        plt.xlabel('The %s' % x_label)\n",
    "        print (\"X: %s, Y: %s\" % (x1,y_values))\n",
    "        plt.xticks(x1, x2,rotation=45)\n",
    "        print \"X: %s, Y: %s\" % (len(x1),len(y_values))\n",
    "        plt.bar(x1, y_values,log=True)\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The following shows all the histograms for all of the features. \n",
    "def show_all_histograms(x,y,featureType,z_other_value=0):\n",
    "    isCategory = True\n",
    "     \n",
    "    if featureType==\"Integer\":\n",
    "        isCategory = False\n",
    "       \n",
    "        for i in range(len(x)):\n",
    "            disp_Histogram(x[i],y[i],isCategory,i,z_other_value=0)\n",
    "    else:\n",
    "        isCategory = True\n",
    "        for i in range(len(x)):\n",
    "            #print z_other_value[i]\n",
    "            disp_Histogram(x[i],y[i],isCategory,i,z_other_value[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This computes the Mean, StDev, Kurtosis, and Skewness for each Integer Feature. \n",
    "\n",
    "It outputs the results for 13 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_column_summary_details(col_num, mean,std,kurtosis, skewness):\n",
    "    print(\"Column #%2d: mean=%-10.3f std=%-10.3f Kurtosis=%-10.3f Skewness=%-10.3f\" % (col_num, mean,std, kurtosis, skewness))\n",
    "\n",
    "def int_columns_detail_stats(data):\n",
    "    df = sqlContext.createDataFrame(data)\n",
    "    for i, col in enumerate(column_iter(data)):\n",
    "        col_num = i + 1\n",
    "        if is_integer_col_num(col_num):            \n",
    "            col = df[\"_%s\" % col_num]\n",
    "            m_col = sqlFunctions.mean(col)\n",
    "            m_results = df.select(m_col.alias(\"mean\")).collect()[0]\n",
    "            std_col = sqlFunctions.stddev(col)\n",
    "            std_results = df.select(std_col.alias(\"stddev\")).collect()[0]\n",
    "            k_col = sqlFunctions.kurtosis(col)\n",
    "            k_result = df.select(k_col.alias(\"kurtosis\")).collect()[0]\n",
    "            s_col = sqlFunctions.skewness(col)\n",
    "            s_result = df.select(s_col.alias(\"skewness\")).collect()[0]\n",
    "            \n",
    "            print_column_summary_details(col_num, m_results.mean,std_results.stddev,k_result.kurtosis, s_result.skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following functions compute the Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This code computes the histograms based on the training sets.\n",
    "#The code computes 10 bins by default.\n",
    "numb_bins=10\n",
    "x_int_val, y_int_val =int_columns_histograms(train_5m,numb_bins)\n",
    "show_all_histograms(x_int_val,y_int_val,\"Integer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute and display Integer Summary Statistics, Mean, Stdev, Skewness, Kurtosis)\n",
    "int_columns_detail_stats(train_5m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute and display Category Histograms\n",
    "numb_bins=10\n",
    "hashes, counts, remainder =cat_columns_histogram(train_5m,numb_bins)\n",
    "show_all_histograms(hashes, counts,\"Category\",remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
